# API
API_PORT=3001
# TRUST_PROXY controls which proxy IPs are trusted for deriving `req.ip`.
# - true/false | hop-count | comma-separated CIDRs
TRUST_PROXY=127.0.0.1/8,10.0.0.0/8,172.16.0.0/12,192.168.0.0/16,::1/128,fc00::/7

# Risk control (rate limit / anonymity)
# In production, RISK_IP_HASH_SALT must be a strong secret (>=16 chars, non-default).
RISK_IP_HASH_SALT=change-me-change-me
RISK_RL_WINDOW_SECONDS=60
RISK_RL_CREATE_TOPIC_IP_LIMIT=10

# DB
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/epiphany

# Redis
REDIS_URL=redis://localhost:6379

# Web
NEXT_PUBLIC_API_URL=http://localhost:3001

# OpenRouter (AI Provider)
OPENROUTER_API_KEY=sk-or-v1-your-key-here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# AI Models (via OpenRouter)
EMBEDDING_MODEL=qwen/qwen3-embedding-8b
STANCE_MODEL=google/gemini-2.5-flash-preview
TOPIC_TITLE_MODEL=google/gemini-3-flash-preview
REPORT_MODEL=deepseek/deepseek-chat-v3-0324

# Translation (zh/en)
# - Independent from AI_PROVIDER; set explicitly if you only want translation to use OpenRouter.
TRANSLATION_PROVIDER=openrouter
TRANSLATION_MODEL=z-ai/glm-4.7
# Hard budget gate to avoid overspending (see docs/stage04/translation-module-spec.md)
TRANSLATION_BUDGET_TOKENS_PER_MONTH=200000
# Backfill + sweeper (auto-enqueue missing/stale translations)
# TRANSLATION_AUTOMATION_ENABLED=1
# TRANSLATION_BACKFILL_MODE=auto # auto|force|disabled
# TRANSLATION_SWEEPER_INTERVAL_MS=300000
# TRANSLATION_SWEEPER_BATCH_SIZE=200
# TRANSLATION_SWEEPER_ENQUEUE_CONCURRENCY=10
# Run automation even when TRANSLATION_PROVIDER=mock
# TRANSLATION_AUTOMATION_ALLOW_MOCK=0
# Optional tuning
# TRANSLATION_TIMEOUT_MS=90000
# TRANSLATION_TEMPERATURE=0.1
# TRANSLATION_MAX_TOKENS=4096

# Topic title auto-generation (if create-topic title is left blank)
# TOPIC_TITLE_TIMEOUT_MS=15000
# TOPIC_TITLE_TEMPERATURE=0.2
# TOPIC_TITLE_MAX_TOKENS=64
# TOPIC_TITLE_INPUT_MAX_CHARS=2000
# Title length constraint (characters)
# TOPIC_TITLE_OUTPUT_MIN_CHARS=2
# TOPIC_TITLE_OUTPUT_MAX_CHARS=10

# Clustering
CLUSTER_ENGINE=node

# Worker (debug endpoints)
# If set, POST /enqueue-analysis requires X-Worker-Debug-Token header to match.
# WORKER_DEBUG_TOKEN=
